{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision.models import efficientnet_b0\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "from torchvision.datasets import CIFAR10\n",
    "import time\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "train_dataset = CIFAR10(root=\"./data\", train=True,\n",
    "                        download=True, transform=transform)\n",
    "test_dataset = CIFAR10(root=\"./data\", train=False,\n",
    "                        download=True, transform=transform)\n",
    "train_data_size = len(train_dataset)\n",
    "test_data_size = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_valid(model, loss_function, optimizer, epochs=25):\n",
    "    history = list()\n",
    "    best_acc = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        epoch_start = time.time()\n",
    "        print(\"Epoch: {}/{}\".format(epoch+1, epochs))\n",
    "\n",
    "        model.train()\n",
    "\n",
    "        train_loss = 0.0\n",
    "        train_acc = 0.0\n",
    "        test_loss = 0.0\n",
    "        test_acc = 0.0\n",
    "\n",
    "        for inputs, labels in tqdm(train_dataloader,total=len(train_dataloader)):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_function(outputs,labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item() * inputs.size(0)\n",
    "            ret, predictions = torch.max(outputs.data,1)\n",
    "            correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "            acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "            train_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "\n",
    "            for inputs, labels in tqdm(test_dataloader,total=len(test_dataloader)):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = loss_function(outputs, labels)\n",
    "\n",
    "                test_loss += loss.item() * inputs.size(0)\n",
    "                ret, predictions = torch.max(outputs.data, 1)\n",
    "                correct_counts = predictions.eq(labels.data.view_as(predictions))\n",
    "                acc = torch.mean(correct_counts.type(torch.FloatTensor))\n",
    "                test_acc += acc.item() * inputs.size(0)\n",
    "\n",
    "        avg_train_loss = train_loss/train_data_size\n",
    "        avg_train_acc = train_acc/train_data_size\n",
    "        avg_test_loss = test_loss/test_data_size\n",
    "        avg_test_acc = test_acc/test_data_size\n",
    "\n",
    "        history.append([avg_train_loss, avg_test_loss, avg_train_acc, avg_test_acc])\n",
    "\n",
    "        if best_acc < avg_test_acc:\n",
    "            best_acc = avg_test_acc\n",
    "            best_epoch = epoch + 1\n",
    "            torch.save(model.state_dict(), 'weights/best_model.pth')\n",
    "            \n",
    "\n",
    "        epoch_end = time.time()\n",
    "\n",
    "        print(\"Epoch: {:03d}, Training: Loss: {:.4f}, Accuracy: {:.4f}%, \\n\\t\\Test: Loss: {:.4f}, Accuracy: {:.4f}%, Time: {:.4f}s\".format(\n",
    "            epoch+1, avg_test_loss, avg_train_acc*100, avg_test_loss, avg_test_acc*100, epoch_end-epoch_start\n",
    "        ))\n",
    "        print(\"Best Accuracy for validation : {:.4f} at epoch {:03d}\".format(best_acc, best_epoch))\n",
    "\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [06:38<00:00,  3.92it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 19.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Training: Loss: 0.2970, Accuracy: 83.5560%, \n",
      "\t\\Test: Loss: 0.2970, Accuracy: 89.9700%, Time: 414.5447s\n",
      "Best Accuracy for validation : 0.8997 at epoch 001\n",
      "Epoch: 2/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [03:54<00:00,  6.66it/s]\n",
      "100%|██████████| 313/313 [00:17<00:00, 18.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 002, Training: Loss: 0.3840, Accuracy: 89.3860%, \n",
      "\t\\Test: Loss: 0.3840, Accuracy: 88.4800%, Time: 252.0304s\n",
      "Best Accuracy for validation : 0.8997 at epoch 001\n",
      "Epoch: 3/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [03:58<00:00,  6.56it/s]\n",
      "100%|██████████| 313/313 [00:16<00:00, 18.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 003, Training: Loss: 0.2462, Accuracy: 91.4340%, \n",
      "\t\\Test: Loss: 0.2462, Accuracy: 92.0000%, Time: 255.2438s\n",
      "Best Accuracy for validation : 0.9200 at epoch 003\n",
      "Epoch: 4/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [04:00<00:00,  6.50it/s]\n",
      "100%|██████████| 313/313 [00:19<00:00, 15.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 004, Training: Loss: 0.2431, Accuracy: 93.1240%, \n",
      "\t\\Test: Loss: 0.2431, Accuracy: 92.4200%, Time: 260.5830s\n",
      "Best Accuracy for validation : 0.9242 at epoch 004\n",
      "Epoch: 5/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [07:43<00:00,  3.37it/s]\n",
      "100%|██████████| 313/313 [00:29<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 005, Training: Loss: 0.2361, Accuracy: 93.5160%, \n",
      "\t\\Test: Loss: 0.2361, Accuracy: 92.5800%, Time: 493.2817s\n",
      "Best Accuracy for validation : 0.9258 at epoch 005\n",
      "Epoch: 6/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [06:14<00:00,  4.18it/s]\n",
      "100%|██████████| 313/313 [00:35<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 006, Training: Loss: 0.2212, Accuracy: 94.6000%, \n",
      "\t\\Test: Loss: 0.2212, Accuracy: 93.2500%, Time: 410.1637s\n",
      "Best Accuracy for validation : 0.9325 at epoch 006\n",
      "Epoch: 7/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:40<00:00,  2.44it/s]\n",
      "100%|██████████| 313/313 [00:37<00:00,  8.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 007, Training: Loss: 0.2250, Accuracy: 95.3960%, \n",
      "\t\\Test: Loss: 0.2250, Accuracy: 93.2400%, Time: 678.8317s\n",
      "Best Accuracy for validation : 0.9325 at epoch 006\n",
      "Epoch: 8/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:30<00:00,  2.48it/s]\n",
      "100%|██████████| 313/313 [00:34<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 008, Training: Loss: 0.2264, Accuracy: 95.8040%, \n",
      "\t\\Test: Loss: 0.2264, Accuracy: 92.9800%, Time: 665.4034s\n",
      "Best Accuracy for validation : 0.9325 at epoch 006\n",
      "Epoch: 9/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:42<00:00,  2.43it/s]\n",
      "100%|██████████| 313/313 [00:35<00:00,  8.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 009, Training: Loss: 0.2255, Accuracy: 96.2760%, \n",
      "\t\\Test: Loss: 0.2255, Accuracy: 93.5400%, Time: 677.9765s\n",
      "Best Accuracy for validation : 0.9354 at epoch 009\n",
      "Epoch: 10/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:45<00:00,  2.42it/s]\n",
      "100%|██████████| 313/313 [00:31<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 010, Training: Loss: 0.3165, Accuracy: 96.5680%, \n",
      "\t\\Test: Loss: 0.3165, Accuracy: 92.0900%, Time: 677.5913s\n",
      "Best Accuracy for validation : 0.9354 at epoch 009\n",
      "Epoch: 11/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [09:56<00:00,  2.62it/s]\n",
      "100%|██████████| 313/313 [00:36<00:00,  8.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 011, Training: Loss: 0.2815, Accuracy: 96.8080%, \n",
      "\t\\Test: Loss: 0.2815, Accuracy: 92.6000%, Time: 633.2906s\n",
      "Best Accuracy for validation : 0.9354 at epoch 009\n",
      "Epoch: 12/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:44<00:00,  2.43it/s]\n",
      "100%|██████████| 313/313 [00:37<00:00,  8.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 012, Training: Loss: 0.2992, Accuracy: 96.9760%, \n",
      "\t\\Test: Loss: 0.2992, Accuracy: 92.6000%, Time: 682.0001s\n",
      "Best Accuracy for validation : 0.9354 at epoch 009\n",
      "Epoch: 13/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [10:12<00:00,  2.55it/s]\n",
      "100%|██████████| 313/313 [00:35<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 013, Training: Loss: 0.2493, Accuracy: 97.2720%, \n",
      "\t\\Test: Loss: 0.2493, Accuracy: 93.4000%, Time: 648.0194s\n",
      "Best Accuracy for validation : 0.9354 at epoch 009\n",
      "Epoch: 14/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 1140/1563 [07:29<02:46,  2.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [5], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m loss_func \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mCrossEntropyLoss()\n\u001b[0;32m      6\u001b[0m optimizer \u001b[39m=\u001b[39m optim\u001b[39m.\u001b[39mAdam(model\u001b[39m.\u001b[39mparameters())\n\u001b[1;32m----> 7\u001b[0m trained_model, history \u001b[39m=\u001b[39m train_and_valid(model, loss_func, optimizer, num_epochs)\n",
      "Cell \u001b[1;32mIn [4], line 25\u001b[0m, in \u001b[0;36mtrain_and_valid\u001b[1;34m(model, loss_function, optimizer, epochs)\u001b[0m\n\u001b[0;32m     23\u001b[0m loss \u001b[39m=\u001b[39m loss_function(outputs,labels)\n\u001b[0;32m     24\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n\u001b[1;32m---> 25\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()\n\u001b[0;32m     26\u001b[0m train_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss\u001b[39m.\u001b[39mitem() \u001b[39m*\u001b[39m inputs\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n\u001b[0;32m     27\u001b[0m ret, predictions \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata,\u001b[39m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[1;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mmax_exp_avg_sq\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[0;32m    155\u001b[0m             state_steps\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m--> 157\u001b[0m     adam(params_with_grad,\n\u001b[0;32m    158\u001b[0m          grads,\n\u001b[0;32m    159\u001b[0m          exp_avgs,\n\u001b[0;32m    160\u001b[0m          exp_avg_sqs,\n\u001b[0;32m    161\u001b[0m          max_exp_avg_sqs,\n\u001b[0;32m    162\u001b[0m          state_steps,\n\u001b[0;32m    163\u001b[0m          amsgrad\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mamsgrad\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    164\u001b[0m          beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    165\u001b[0m          beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    166\u001b[0m          lr\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mlr\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    167\u001b[0m          weight_decay\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mweight_decay\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    168\u001b[0m          eps\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39meps\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    169\u001b[0m          maximize\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mmaximize\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    170\u001b[0m          foreach\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mforeach\u001b[39;49m\u001b[39m'\u001b[39;49m],\n\u001b[0;32m    171\u001b[0m          capturable\u001b[39m=\u001b[39;49mgroup[\u001b[39m'\u001b[39;49m\u001b[39mcapturable\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m    173\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    211\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adam\n\u001b[1;32m--> 213\u001b[0m func(params,\n\u001b[0;32m    214\u001b[0m      grads,\n\u001b[0;32m    215\u001b[0m      exp_avgs,\n\u001b[0;32m    216\u001b[0m      exp_avg_sqs,\n\u001b[0;32m    217\u001b[0m      max_exp_avg_sqs,\n\u001b[0;32m    218\u001b[0m      state_steps,\n\u001b[0;32m    219\u001b[0m      amsgrad\u001b[39m=\u001b[39;49mamsgrad,\n\u001b[0;32m    220\u001b[0m      beta1\u001b[39m=\u001b[39;49mbeta1,\n\u001b[0;32m    221\u001b[0m      beta2\u001b[39m=\u001b[39;49mbeta2,\n\u001b[0;32m    222\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[0;32m    223\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[0;32m    224\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[0;32m    225\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize,\n\u001b[0;32m    226\u001b[0m      capturable\u001b[39m=\u001b[39;49mcapturable)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\optim\\adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[0;32m    261\u001b[0m \u001b[39m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[0;32m    262\u001b[0m exp_avg\u001b[39m.\u001b[39mmul_(beta1)\u001b[39m.\u001b[39madd_(grad, alpha\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m beta1)\n\u001b[1;32m--> 263\u001b[0m exp_avg_sq\u001b[39m.\u001b[39;49mmul_(beta2)\u001b[39m.\u001b[39;49maddcmul_(grad, grad\u001b[39m.\u001b[39;49mconj(), value\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m beta2)\n\u001b[0;32m    265\u001b[0m \u001b[39mif\u001b[39;00m capturable:\n\u001b[0;32m    266\u001b[0m     step \u001b[39m=\u001b[39m step_t\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = efficientnet_b0(pretrained=True)\n",
    "model.classifier.linear = nn.Linear(1000, 10)\n",
    "model.to(device)\n",
    "num_epochs = 30\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "trained_model, history = train_and_valid(model, loss_func, optimizer, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1050a06cbaeed8b46d187604389f32b45fa537b377a0b8f76b38e0c23b5abbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

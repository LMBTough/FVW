{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import pickle as pkl\n",
    "from tqdm.notebook import tqdm\n",
    "from model.resnet_cifar10 import resnet56\n",
    "from attack import attack, test_model, parse_param\n",
    "import random\n",
    "from fgsm import FGSMGrad\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "setup_seed(3407)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet56():\n",
    "    model = resnet56()\n",
    "    state_dict = torch.load(\"weights/checkpoint_best.pth\")[\"state_dict\"]\n",
    "    for key in list(state_dict.keys()):\n",
    "        if key.startswith('module.'):\n",
    "            state_dict[key[7:]] = state_dict[key]\n",
    "            del state_dict[key]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_min = np.min((0 - np.array([0.485, 0.456, 0.406])) /\n",
    "                  np.array([0.229, 0.224, 0.225]))\n",
    "data_max = np.max((1 - np.array([0.485, 0.456, 0.406])) /\n",
    "                  np.array([0.229, 0.224, 0.225]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm = FGSMGrad(0.3 * 255, data_min, data_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_cifar10, load_cifar100\n",
    "from models.resnet import load_cifar10_resnet50, load_cifar100_resnet50\n",
    "model = load_resnet56()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_param_names = list()\n",
    "for name, param in model.named_parameters():\n",
    "    if not \"bn\" in name:\n",
    "        all_param_names.append(name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_param_names = all_param_names[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loaders, test_dataloaders, train_dataloader_all, test_dataloader_all = load_cifar10()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff251a66b96449ba15d2d2f6a422b74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "adv_data_1k = list()\n",
    "adv_true_label_1k = list()\n",
    "from tqdm.notebook import tqdm\n",
    "pbar = tqdm(total=1000)\n",
    "for data, target in train_dataloader_all:\n",
    "    data = data.to(device)\n",
    "    target = target.to(device)\n",
    "    correct_index = torch.argmax(model(data), dim=-1) == target\n",
    "    data = data[correct_index]\n",
    "    target = target[correct_index]\n",
    "    adv_data, success, _, _, _ = fgsm(\n",
    "        model, data, target, num_steps=20, alpha=0.001, early_stop=False, use_sign=True, use_softmax=True)\n",
    "    adv_data_1k.append(adv_data[success])\n",
    "    adv_true_label_1k.append(target[success])\n",
    "    pbar.update(adv_data[success].shape[0])\n",
    "    if pbar.n >= 1000:\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adv_dataset = TensorDataset(torch.cat(adv_data_1k, dim=0), torch.cat(adv_true_label_1k, dim=0))\n",
    "adv_dataloader = DataLoader(adv_dataset, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_totals = list()\n",
    "# for i in range(10):\n",
    "#     all_totals.append(attack(train_loaders[i], all_param_names,\n",
    "#                       load_resnet56, train_dataloader_all, alpha=0.0001, num_steps=2, op=\"add\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pkl.dump(all_totals, open(\"weights/resnet56.pkl\", \"wb\"))\n",
    "all_totals = pkl.load(open(\"weights/resnet56.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zhang\\AppData\\Local\\Temp\\ipykernel_39504\\414253364.py:13: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  combine = np.array(combine)\n"
     ]
    }
   ],
   "source": [
    "thre = 0.045\n",
    "net = load_resnet56()\n",
    "param_remove = dict()\n",
    "for param in all_param_names:\n",
    "    param_remove[param] = None\n",
    "for i in range(len(all_totals)):\n",
    "    totals = all_totals[i]\n",
    "    totals = [totals[param] for param in all_param_names]\n",
    "    param_weights = [eval(\"net.\" + parse_param(param) + \".cpu().detach().numpy()\")\n",
    "                     for param in all_param_names]\n",
    "    combine = [np.abs(total * weight)\n",
    "               for total, weight in zip(totals, param_weights)]\n",
    "    combine = np.array(combine)\n",
    "    combine_flatten = np.concatenate(\n",
    "        [combine_.flatten() for combine_ in combine], axis=0)\n",
    "    threshold = np.sort(combine_flatten)[\n",
    "        ::-1][int(len(combine_flatten) * thre)]\n",
    "    for idx, param in enumerate(all_param_names):\n",
    "        if param_remove[param] is None:\n",
    "            param_remove[param] = combine[idx] > threshold\n",
    "        else:\n",
    "            t = combine[idx] > threshold\n",
    "            param_remove[param] = param_remove[param] | t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight 0.5648148148148148\n",
      "layer1.0.conv1.weight 0.1762152777777778\n",
      "layer1.0.conv2.weight 0.1918402777777778\n",
      "layer1.1.conv1.weight 0.1015625\n",
      "layer1.1.conv2.weight 0.07942708333333333\n",
      "layer1.2.conv1.weight 0.16796875\n",
      "layer1.2.conv2.weight 0.11067708333333333\n",
      "layer1.3.conv1.weight 0.015190972222222222\n",
      "layer1.3.conv2.weight 0.0013020833333333333\n",
      "layer1.4.conv1.weight 0.08463541666666667\n",
      "layer1.4.conv2.weight 0.016927083333333332\n",
      "layer1.5.conv1.weight 0.0008680555555555555\n",
      "layer1.5.conv2.weight 0.0\n",
      "layer1.6.conv1.weight 0.19270833333333334\n",
      "layer1.6.conv2.weight 0.140625\n",
      "layer1.7.conv1.weight 0.18663194444444445\n",
      "layer1.7.conv2.weight 0.07378472222222222\n",
      "layer1.8.conv1.weight 0.2881944444444444\n",
      "layer1.8.conv2.weight 0.15364583333333334\n",
      "layer2.0.conv1.weight 0.2827690972222222\n",
      "layer2.0.conv2.weight 0.059895833333333336\n",
      "layer2.1.conv1.weight 0.0\n",
      "layer2.1.conv2.weight 0.0\n",
      "layer2.2.conv1.weight 0.0\n",
      "layer2.2.conv2.weight 0.0\n",
      "layer2.3.conv1.weight 0.0\n",
      "layer2.3.conv2.weight 0.0\n",
      "layer2.4.conv1.weight 0.024739583333333332\n",
      "layer2.4.conv2.weight 0.014539930555555556\n",
      "layer2.5.conv1.weight 0.1763237847222222\n",
      "layer2.5.conv2.weight 0.11046006944444445\n",
      "layer2.6.conv1.weight 0.2573784722222222\n",
      "layer2.6.conv2.weight 0.18782552083333334\n",
      "layer2.7.conv1.weight 0.3301866319444444\n",
      "layer2.7.conv2.weight 0.3619791666666667\n",
      "layer2.8.conv1.weight 0.5695529513888888\n",
      "layer2.8.conv2.weight 0.4048394097222222\n",
      "layer3.0.conv1.weight 0.5077582465277778\n",
      "layer3.0.conv2.weight 0.2854546440972222\n",
      "layer3.1.conv1.weight 0.14803059895833334\n",
      "layer3.1.conv2.weight 0.0820041232638889\n",
      "layer3.2.conv1.weight 0.1294216579861111\n",
      "layer3.2.conv2.weight 0.075927734375\n",
      "layer3.3.conv1.weight 0.1767306857638889\n",
      "layer3.3.conv2.weight 0.07014973958333333\n",
      "layer3.4.conv1.weight 0.1984320746527778\n",
      "layer3.4.conv2.weight 0.07438151041666667\n",
      "layer3.5.conv1.weight 0.18603515625\n",
      "layer3.5.conv2.weight 0.071044921875\n",
      "layer3.6.conv1.weight 0.21044921875\n",
      "layer3.6.conv2.weight 0.08902994791666667\n",
      "layer3.7.conv1.weight 0.23130967881944445\n",
      "layer3.7.conv2.weight 0.0939670138888889\n",
      "layer3.8.conv1.weight 0.2634819878472222\n",
      "layer3.8.conv2.weight 0.0810275607638889\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "all_num = 0\n",
    "for param in param_remove:\n",
    "    temp += param_remove[param].sum()\n",
    "    all_num += param_remove[param].size\n",
    "    print(param, param_remove[param].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15257619909843642"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp / all_num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始准确率 0.9325\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_resnet56()\n",
    "    preds, labels = test_model(net, test_dataloader_all)\n",
    "    print(\"原始准确率\", (preds.argmax(-1) == labels).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在准确率 0.1\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_resnet56()\n",
    "    for param in all_param_names:\n",
    "        param_ = parse_param(param)\n",
    "        try:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param]] = 0\")\n",
    "        except:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param],:] = 0\")\n",
    "    preds, labels = test_model(net, test_dataloader_all)\n",
    "    print(\"现在准确率\", (preds.argmax(-1) == labels).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "抗进攻准确率 0.19288389513108614\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_resnet56()\n",
    "    for param in all_param_names:\n",
    "        param_ = parse_param(param)\n",
    "        try:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param]] = 0\")\n",
    "        except:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param],:] = 0\")\n",
    "    preds, labels = test_model(net, adv_dataloader)\n",
    "    print(\"抗进攻准确率\", (preds.argmax(-1) == labels).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(train_dataloader, test_dataloader, model, epochs=10, lr=0.001, masks=None, save_path=\"weights/best_model.pth\"):\n",
    "    loss_func = nn.CrossEntropyLoss(reduction=\"sum\")\n",
    "    best_acc = -np.inf\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        num = 0\n",
    "        for x, y in tqdm(train_dataloader):\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            output = model(x)\n",
    "            loss = loss_func(output, y)\n",
    "            # regularization_loss = 0\n",
    "            # for param in model.parameters():\n",
    "            #     regularization_loss += torch.norm(param)\n",
    "            # loss = loss + 0.1 * regularization_loss\n",
    "            loss.backward()\n",
    "            for name, param in model.named_parameters():\n",
    "                if masks is not None:\n",
    "                    name = parse_param(name)\n",
    "                    if name in masks.keys():\n",
    "                        param.grad = param.grad * \\\n",
    "                            torch.BoolTensor(masks[name]).to(device)\n",
    "                        # print(name)\n",
    "                        # print(name, param.grad)\n",
    "                # print(name, param.shape)\n",
    "                param.data -= lr * param.grad\n",
    "                param.grad.zero_()\n",
    "        model.eval()\n",
    "        train_pred, train_label = test_model(model, train_dataloader)\n",
    "        test_pred, test_label = test_model(model, test_dataloader)\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} train acc: {(train_pred.argmax(-1) == train_label).mean()}\")\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1} test acc: {(test_pred.argmax(-1) == test_label).mean()}\")\n",
    "        if (test_pred.argmax(-1) == test_label).mean() > best_acc:\n",
    "            best_acc = (test_pred.argmax(-1) == test_label).mean()\n",
    "            torch.save(model.state_dict(), save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78711db1c8404f8692b899f1ce2ef389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train acc: 0.95434\n",
      "Epoch 1 test acc: 0.8883\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0174348abc54c71a5802c597bf0465e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train acc: 0.9689\n",
      "Epoch 2 test acc: 0.8901\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae34e4019c3746809223f01bb9fa87a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train acc: 0.98122\n",
      "Epoch 3 test acc: 0.9013\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4d9b33dbb614ac4bc6d2c99defc3ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train acc: 0.99044\n",
      "Epoch 4 test acc: 0.9009\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ced75982d44cef969e7d6ae9334cc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train acc: 0.99546\n",
      "Epoch 5 test acc: 0.9063\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4448ae8615264358a2fad855ebf1947f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [34], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(train_dataloader_all, test_dataloader_all,\n\u001b[0;32m      2\u001b[0m             net, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.0005\u001b[39;49m, masks\u001b[39m=\u001b[39;49mparam_remove)\n",
      "Cell \u001b[1;32mIn [28], line 17\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_dataloader, test_dataloader, model, epochs, lr, masks, save_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m loss \u001b[39m=\u001b[39m loss_func(output, y)\n\u001b[0;32m     13\u001b[0m \u001b[39m# regularization_loss = 0\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[39m# for param in model.parameters():\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[39m#     regularization_loss += torch.norm(param)\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[39m# loss = loss + 0.1 * regularization_loss\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[0;32m     18\u001b[0m \u001b[39mfor\u001b[39;00m name, param \u001b[39min\u001b[39;00m model\u001b[39m.\u001b[39mnamed_parameters():\n\u001b[0;32m     19\u001b[0m     \u001b[39mif\u001b[39;00m masks \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[0;32m    388\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    389\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[0;32m    390\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    394\u001b[0m         create_graph\u001b[39m=\u001b[39mcreate_graph,\n\u001b[0;32m    395\u001b[0m         inputs\u001b[39m=\u001b[39minputs)\n\u001b[1;32m--> 396\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\autograd\\__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    168\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[0;32m    170\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    171\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    172\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 173\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    174\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[0;32m    175\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(train_dataloader_all, test_dataloader_all,\n",
    "            net, epochs=100, lr=0.0005, masks=param_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在准确率 0.0982\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = resnet56()\n",
    "    net.to(device)\n",
    "    net.eval()\n",
    "    for param in all_param_names:\n",
    "        param_ = parse_param(param)\n",
    "        try:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param]] = 0\")\n",
    "        except:\n",
    "            exec(\"net.\" + param_ + \"[~param_remove[param],:] = 0\")\n",
    "    preds, labels = test_model(net, test_dataloader_all)\n",
    "    print(\"现在准确率\", (preds.argmax(-1) == labels).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af54d51246e4fa9aac0a619ba0a3527",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train acc: 0.48392\n",
      "Epoch 1 test acc: 0.4837\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815a3be9f8df4815bae34832f21b8d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train acc: 0.52886\n",
      "Epoch 2 test acc: 0.5156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e73e47541204aaf9645909cad00681a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train acc: 0.62882\n",
      "Epoch 3 test acc: 0.6106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c5e79c354db460a83d777b6c8d06f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train acc: 0.64616\n",
      "Epoch 4 test acc: 0.6276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23d81dcc821e4dcbaa94cd458c87fce4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 train acc: 0.64282\n",
      "Epoch 5 test acc: 0.6115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bd94a273be74fbfa2b039f2b2ef88a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 train acc: 0.73112\n",
      "Epoch 6 test acc: 0.6881\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e35f5874d47461caa74b1fa1c6fb27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 train acc: 0.79846\n",
      "Epoch 7 test acc: 0.7367\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c957b8c665884da6aa0a47205fa4064f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 train acc: 0.77864\n",
      "Epoch 8 test acc: 0.72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "341d13eb91cd4efca0dbf50bf7363e89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 train acc: 0.8278\n",
      "Epoch 9 test acc: 0.7524\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73a72da1e92740689b103a6c78b43f59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 train acc: 0.85272\n",
      "Epoch 10 test acc: 0.7557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e289d39ddf4c5f82d34bbe4e3931fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 train acc: 0.83884\n",
      "Epoch 11 test acc: 0.7401\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3244c5d7a2bb454193a7b7ee139b6ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 train acc: 0.8513\n",
      "Epoch 12 test acc: 0.7444\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66d095aa40844eb4915a193741cfac83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 train acc: 0.89014\n",
      "Epoch 13 test acc: 0.7551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bcf3a223af4297a2f8428f5ad19110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/196 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_model(train_dataloader_all, test_dataloader_all,\n\u001b[0;32m      2\u001b[0m             net, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, lr\u001b[39m=\u001b[39;49m\u001b[39m0.0005\u001b[39;49m, masks\u001b[39m=\u001b[39;49mparam_remove)\n",
      "Cell \u001b[1;32mIn [28], line 9\u001b[0m, in \u001b[0;36mtrain_model\u001b[1;34m(train_dataloader, test_dataloader, model, epochs, lr, masks, save_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m all_labels \u001b[39m=\u001b[39m []\n\u001b[0;32m      8\u001b[0m num \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m----> 9\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m tqdm(train_dataloader):\n\u001b[0;32m     10\u001b[0m     x, y \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mto(device), y\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m     output \u001b[39m=\u001b[39m model(x)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\notebook.py:259\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    258\u001b[0m     it \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39m(tqdm_notebook, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m()\n\u001b[1;32m--> 259\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m it:\n\u001b[0;32m    260\u001b[0m         \u001b[39m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    261\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m    262\u001b[0m \u001b[39m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:681\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    679\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    680\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 681\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    682\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    683\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    684\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    685\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:721\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    720\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    722\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    723\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\datasets\\cifar.py:118\u001b[0m, in \u001b[0;36mCIFAR10.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m    115\u001b[0m img \u001b[39m=\u001b[39m Image\u001b[39m.\u001b[39mfromarray(img)\n\u001b[0;32m    117\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 118\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform(img)\n\u001b[0;32m    120\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    121\u001b[0m     target \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_transform(target)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:94\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     93\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 94\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     95\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\transforms.py:134\u001b[0m, in \u001b[0;36mToTensor.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    126\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    127\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    128\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    129\u001b[0m \u001b[39m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[39m        Tensor: Converted image.\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 134\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_tensor(pic)\n",
      "File \u001b[1;32mc:\\Users\\Zhang\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\transforms\\functional.py:168\u001b[0m, in \u001b[0;36mto_tensor\u001b[1;34m(pic)\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m1\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    167\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39m255\u001b[39m \u001b[39m*\u001b[39m img\n\u001b[1;32m--> 168\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39;49mview(pic\u001b[39m.\u001b[39;49msize[\u001b[39m1\u001b[39;49m], pic\u001b[39m.\u001b[39;49msize[\u001b[39m0\u001b[39;49m], \u001b[39mlen\u001b[39;49m(pic\u001b[39m.\u001b[39;49mgetbands()))\n\u001b[0;32m    169\u001b[0m \u001b[39m# put it from HWC to CHW format\u001b[39;00m\n\u001b[0;32m    170\u001b[0m img \u001b[39m=\u001b[39m img\u001b[39m.\u001b[39mpermute((\u001b[39m2\u001b[39m, \u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m))\u001b[39m.\u001b[39mcontiguous()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(train_dataloader_all, test_dataloader_all,\n",
    "            net, epochs=100, lr=0.0005, masks=param_remove)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c1050a06cbaeed8b46d187604389f32b45fa537b377a0b8f76b38e0c23b5abbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

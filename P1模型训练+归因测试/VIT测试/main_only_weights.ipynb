{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import VisionTransformer\n",
    "import re\n",
    "import torch\n",
    "from datasets import load_cifar10\n",
    "from attack import attack,test_model\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    model = VisionTransformer(\n",
    "                image_size=(384, 384),\n",
    "                patch_size=(16, 16),\n",
    "                emb_dim=768,\n",
    "                mlp_dim=3072,\n",
    "                num_heads=12,\n",
    "                num_layers=12,\n",
    "                num_classes=10,\n",
    "                attn_dropout_rate=0.0,\n",
    "                dropout_rate=0.1)\n",
    "    state_dict = torch.load(\"weights/best.pth\")[\"state_dict\"]\n",
    "    model.load_state_dict(state_dict)\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cls_token torch.Size([1, 1, 768])\n",
      "embedding.weight torch.Size([768, 3, 16, 16])\n",
      "embedding.bias torch.Size([768])\n",
      "transformer.pos_embedding.pos_embedding torch.Size([1, 577, 768])\n",
      "transformer.encoder_layers.0.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.0.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.0.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.0.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.0.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.0.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.0.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.0.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.0.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.0.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.0.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.0.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.0.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.0.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.0.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.0.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.1.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.1.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.1.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.1.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.1.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.1.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.1.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.1.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.1.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.1.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.1.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.1.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.1.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.1.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.1.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.1.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.2.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.2.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.2.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.2.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.2.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.2.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.2.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.2.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.2.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.2.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.2.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.2.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.2.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.2.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.2.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.2.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.3.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.3.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.3.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.3.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.3.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.3.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.3.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.3.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.3.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.3.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.3.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.3.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.3.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.3.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.3.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.3.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.4.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.4.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.4.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.4.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.4.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.4.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.4.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.4.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.4.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.4.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.4.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.4.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.4.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.4.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.4.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.4.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.5.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.5.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.5.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.5.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.5.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.5.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.5.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.5.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.5.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.5.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.5.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.5.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.5.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.5.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.5.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.5.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.6.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.6.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.6.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.6.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.6.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.6.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.6.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.6.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.6.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.6.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.6.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.6.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.6.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.6.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.6.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.6.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.7.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.7.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.7.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.7.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.7.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.7.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.7.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.7.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.7.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.7.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.7.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.7.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.7.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.7.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.7.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.7.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.8.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.8.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.8.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.8.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.8.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.8.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.8.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.8.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.8.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.8.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.8.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.8.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.8.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.8.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.8.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.8.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.9.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.9.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.9.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.9.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.9.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.9.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.9.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.9.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.9.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.9.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.9.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.9.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.9.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.9.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.9.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.9.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.10.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.10.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.10.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.10.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.10.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.10.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.10.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.10.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.10.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.10.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.10.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.10.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.10.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.10.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.10.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.10.mlp.fc2.bias torch.Size([768])\n",
      "transformer.encoder_layers.11.norm1.weight torch.Size([768])\n",
      "transformer.encoder_layers.11.norm1.bias torch.Size([768])\n",
      "transformer.encoder_layers.11.attn.query.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.11.attn.query.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.11.attn.key.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.11.attn.key.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.11.attn.value.weight torch.Size([768, 12, 64])\n",
      "transformer.encoder_layers.11.attn.value.bias torch.Size([12, 64])\n",
      "transformer.encoder_layers.11.attn.out.weight torch.Size([12, 64, 768])\n",
      "transformer.encoder_layers.11.attn.out.bias torch.Size([768])\n",
      "transformer.encoder_layers.11.norm2.weight torch.Size([768])\n",
      "transformer.encoder_layers.11.norm2.bias torch.Size([768])\n",
      "transformer.encoder_layers.11.mlp.fc1.weight torch.Size([3072, 768])\n",
      "transformer.encoder_layers.11.mlp.fc1.bias torch.Size([3072])\n",
      "transformer.encoder_layers.11.mlp.fc2.weight torch.Size([768, 3072])\n",
      "transformer.encoder_layers.11.mlp.fc2.bias torch.Size([768])\n",
      "transformer.norm.weight torch.Size([768])\n",
      "transformer.norm.bias torch.Size([768])\n",
      "classifier.weight torch.Size([10, 768])\n",
      "classifier.bias torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding',\n",
       " 'transformer.encoder_layers[0].norm1',\n",
       " 'transformer.encoder_layers[0].attn.query',\n",
       " 'transformer.encoder_layers[0].attn.key',\n",
       " 'transformer.encoder_layers[0].attn.value',\n",
       " 'transformer.encoder_layers[0].attn.out',\n",
       " 'transformer.encoder_layers[0].norm2',\n",
       " 'transformer.encoder_layers[0].mlp.fc1',\n",
       " 'transformer.encoder_layers[0].mlp.fc2',\n",
       " 'transformer.encoder_layers[1].norm1',\n",
       " 'transformer.encoder_layers[1].attn.query',\n",
       " 'transformer.encoder_layers[1].attn.key',\n",
       " 'transformer.encoder_layers[1].attn.value',\n",
       " 'transformer.encoder_layers[1].attn.out',\n",
       " 'transformer.encoder_layers[1].norm2',\n",
       " 'transformer.encoder_layers[1].mlp.fc1',\n",
       " 'transformer.encoder_layers[1].mlp.fc2',\n",
       " 'transformer.encoder_layers[2].norm1',\n",
       " 'transformer.encoder_layers[2].attn.query',\n",
       " 'transformer.encoder_layers[2].attn.key',\n",
       " 'transformer.encoder_layers[2].attn.value',\n",
       " 'transformer.encoder_layers[2].attn.out',\n",
       " 'transformer.encoder_layers[2].norm2',\n",
       " 'transformer.encoder_layers[2].mlp.fc1',\n",
       " 'transformer.encoder_layers[2].mlp.fc2',\n",
       " 'transformer.encoder_layers[3].norm1',\n",
       " 'transformer.encoder_layers[3].attn.query',\n",
       " 'transformer.encoder_layers[3].attn.key',\n",
       " 'transformer.encoder_layers[3].attn.value',\n",
       " 'transformer.encoder_layers[3].attn.out',\n",
       " 'transformer.encoder_layers[3].norm2',\n",
       " 'transformer.encoder_layers[3].mlp.fc1',\n",
       " 'transformer.encoder_layers[3].mlp.fc2',\n",
       " 'transformer.encoder_layers[4].norm1',\n",
       " 'transformer.encoder_layers[4].attn.query',\n",
       " 'transformer.encoder_layers[4].attn.key',\n",
       " 'transformer.encoder_layers[4].attn.value',\n",
       " 'transformer.encoder_layers[4].attn.out',\n",
       " 'transformer.encoder_layers[4].norm2',\n",
       " 'transformer.encoder_layers[4].mlp.fc1',\n",
       " 'transformer.encoder_layers[4].mlp.fc2',\n",
       " 'transformer.encoder_layers[5].norm1',\n",
       " 'transformer.encoder_layers[5].attn.query',\n",
       " 'transformer.encoder_layers[5].attn.key',\n",
       " 'transformer.encoder_layers[5].attn.value',\n",
       " 'transformer.encoder_layers[5].attn.out',\n",
       " 'transformer.encoder_layers[5].norm2',\n",
       " 'transformer.encoder_layers[5].mlp.fc1',\n",
       " 'transformer.encoder_layers[5].mlp.fc2',\n",
       " 'transformer.encoder_layers[6].norm1',\n",
       " 'transformer.encoder_layers[6].attn.query',\n",
       " 'transformer.encoder_layers[6].attn.key',\n",
       " 'transformer.encoder_layers[6].attn.value',\n",
       " 'transformer.encoder_layers[6].attn.out',\n",
       " 'transformer.encoder_layers[6].norm2',\n",
       " 'transformer.encoder_layers[6].mlp.fc1',\n",
       " 'transformer.encoder_layers[6].mlp.fc2',\n",
       " 'transformer.encoder_layers[7].norm1',\n",
       " 'transformer.encoder_layers[7].attn.query',\n",
       " 'transformer.encoder_layers[7].attn.key',\n",
       " 'transformer.encoder_layers[7].attn.value',\n",
       " 'transformer.encoder_layers[7].attn.out',\n",
       " 'transformer.encoder_layers[7].norm2',\n",
       " 'transformer.encoder_layers[7].mlp.fc1',\n",
       " 'transformer.encoder_layers[7].mlp.fc2',\n",
       " 'transformer.encoder_layers[8].norm1',\n",
       " 'transformer.encoder_layers[8].attn.query',\n",
       " 'transformer.encoder_layers[8].attn.key',\n",
       " 'transformer.encoder_layers[8].attn.value',\n",
       " 'transformer.encoder_layers[8].attn.out',\n",
       " 'transformer.encoder_layers[8].norm2',\n",
       " 'transformer.encoder_layers[8].mlp.fc1',\n",
       " 'transformer.encoder_layers[8].mlp.fc2',\n",
       " 'transformer.encoder_layers[9].norm1',\n",
       " 'transformer.encoder_layers[9].attn.query',\n",
       " 'transformer.encoder_layers[9].attn.key',\n",
       " 'transformer.encoder_layers[9].attn.value',\n",
       " 'transformer.encoder_layers[9].attn.out',\n",
       " 'transformer.encoder_layers[9].norm2',\n",
       " 'transformer.encoder_layers[9].mlp.fc1',\n",
       " 'transformer.encoder_layers[9].mlp.fc2',\n",
       " 'transformer.encoder_layers[10].norm1',\n",
       " 'transformer.encoder_layers[10].attn.query',\n",
       " 'transformer.encoder_layers[10].attn.key',\n",
       " 'transformer.encoder_layers[10].attn.value',\n",
       " 'transformer.encoder_layers[10].attn.out',\n",
       " 'transformer.encoder_layers[10].norm2',\n",
       " 'transformer.encoder_layers[10].mlp.fc1',\n",
       " 'transformer.encoder_layers[10].mlp.fc2',\n",
       " 'transformer.encoder_layers[11].norm1',\n",
       " 'transformer.encoder_layers[11].attn.query',\n",
       " 'transformer.encoder_layers[11].attn.key',\n",
       " 'transformer.encoder_layers[11].attn.value',\n",
       " 'transformer.encoder_layers[11].attn.out',\n",
       " 'transformer.encoder_layers[11].norm2',\n",
       " 'transformer.encoder_layers[11].mlp.fc1',\n",
       " 'transformer.encoder_layers[11].mlp.fc2',\n",
       " 'transformer.norm',\n",
       " 'classifier']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_layer_names = list()\n",
    "for name,param in model.named_parameters():\n",
    "    if \"weight\" in name:\n",
    "        reg = re.compile(\"\\.\\d+\\.\")\n",
    "        finded = reg.findall(name)\n",
    "        if len(finded) == 0:\n",
    "            all_layer_names.append(name[:-7])\n",
    "        else:\n",
    "            for f in finded:\n",
    "                f = f[1:-1]\n",
    "                name = name.replace(f\".{f}.\", f\"[{f}].\")\n",
    "            all_layer_names.append(name[:-7])\n",
    "all_layer_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_loaders, test_dataloaders, test_dataloader_all = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4639edab03f249bf97c051f638c1723c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(9849, 10000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(model,test_dataloader_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1236cd0fdeee4999bc7f26675f26c55f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.17611303339072e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4055a14716354e2ebc3be076305d854c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02952886368483305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c1ffb5fa514aeaa2434c0b500e263d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6651802265167237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5907532dbaf441f831450a4730a70f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.395269366455079\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1515e50da64175b3d229ceba978030",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.353899447631836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/autodl-tmp/Neural-importance-main/P1模型训练+归因测试/VIT测试/attack.py:51: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  layer_totals = np.array(layer_totals)\n",
      "/root/autodl-tmp/Neural-importance-main/P1模型训练+归因测试/VIT测试/utils.py:188: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x = np.array(x)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb255ab2b3db47e4927af50ee98a8ad7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00017273987938806385\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "587d12295fe340a79ce6f64b842e0ca1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29743441443443297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e735c90e20624cf296ddd5e296cbf7df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.620735089874268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5a889f634642c49b3626ba70a80089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.800572982788086\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b962cf3e19474519b4327a765c40bc71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.997444354248046\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e6a4fcd0b2c4d079074be608804ff4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00026605912309896664\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4649cbdf0304044acfc938a451c28e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01807895293090296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baae7811475840d4b37c18123f80f023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15765635643079876\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f58fcbcafe64bc9bb98bde30197debc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9378524852752685\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbcb57e71ced4ccd930e1d70416131ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.774940203857422\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b90a8efe27d4ccba3b2a05c9849a6c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0023813774497655686\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733b57ce0ea64f16958918ef5f187d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2881590758293867\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4982ffec7074b8c92d54c65e4b22f24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5767861892700195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9cce31bf70b463c86e786e5f71f2e25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.31907311553955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6db157c28c2e481e86b12dcd016d0d2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.74333949584961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ff7a4bb9f94aef892f3a8e73d12a6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0008837171252442204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc0707ffe674865bbb6552140d337c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06307871801811853\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ebaaf3490524ce0bc7f08b8b42a0a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1311324887394907\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f565f00fe3ec4286baa003570bd860e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.453127532958984\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "922d1ba8aaf54159a55ec2cab3237c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.267425317382813\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8d88505a2c94337b10577cab75a1240",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0009060151876648888\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1db5f7e2acc84553965c1504f695d43e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17408443751093\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49e2baf41a3f475d80ce69499f57dd30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9981314842224123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7e039a6b252400794ce6c743f1bc2d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.684711595153809\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33db44ed4e854e06a8c49a654e46f159",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.0784275970459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32affeaf61a94854871d193aa53fdeea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00035041836898817564\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "246f61c2f4464b76a4fe3f32502e995a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3683866453170777\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3b39f671d54e9db7e31430421e522b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.203306437683105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1bb06571dd47c8bf34ca94fe76c251",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.150868743896485\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "068ef73c09c54ce3a5f39ed4df27d2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00012405874358228174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb402f18c85f47d58819864c72d3dd47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02220252730140346\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6200ebe59d514d9799ff75fcdc38126a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8334930953726173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a84b291ba5d44f38af41d0f3f0d8d12a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.376436051940917\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42482fc2f8f4ee2b5a8f29ddb8b7944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.379634716796875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b59fa371a34fecb51c2ed5fb2b18cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0006660923528901435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8ed22e288104025839360e06746a169",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.030550511024927254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7ccb876b70d4e70ac0d2814dda5c48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5538501966476441\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f6f03c472b489390a074f40b6fb499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.933225189208985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2a083033d3f497fac15ccd4163d9d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22.915690103149416\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f673c6668b1e46a1a4049e25b8244373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0007163493095542435\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a79cd3bc77a04634a327b7064d7f45be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2244058738410473\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c264fe72a1a499d9085dd4b42c45610",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.2472744552612305\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6b54de7a144360803036bc6dfa4f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.877379736328123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f9faf142fd24777912cfac91c52a10a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/157 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29.40443511047363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_totals = list()\n",
    "for i in range(10):\n",
    "    all_totals.append(attack(train_loaders[i], all_layer_names, load_model, alpha=0.0001))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "pkl.dump(all_totals, open(\"weights/cifar10_vit_weight.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_104409/3539971323.py:12: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  combine = np.array(combine)\n"
     ]
    }
   ],
   "source": [
    "thre = 0.2\n",
    "net = load_model()\n",
    "layer_remove = dict()\n",
    "for layer in all_layer_names:\n",
    "    layer_remove[layer] = None\n",
    "for i in range(len(all_totals)):\n",
    "    totals = all_totals[i]\n",
    "    totals = [totals[layer] for layer in all_layer_names]\n",
    "    layer_weights = [eval(\"net.\" + layer + \".weight.cpu().detach().numpy()\")\n",
    "                     for layer in all_layer_names]\n",
    "    combine = [np.abs(total * weight) for total, weight in zip(totals, layer_weights)]\n",
    "    combine = np.array(combine)\n",
    "    combine_flatten = np.concatenate([combine_.flatten() for combine_ in combine],axis=0)\n",
    "    threshold = np.sort(combine_flatten)[::-1][int(len(combine_flatten) * thre)]\n",
    "    for idx,layer in enumerate(all_layer_names):\n",
    "        if layer_remove[layer] is None:\n",
    "            layer_remove[layer] = combine[idx] > threshold\n",
    "        else:\n",
    "            t = combine[idx] > threshold\n",
    "            layer_remove[layer] = layer_remove[layer] | t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embedding 0.6393110487196181\n",
      "transformer.encoder_layers[0].norm1 1.0\n",
      "transformer.encoder_layers[0].attn.query 0.3231455485026042\n",
      "transformer.encoder_layers[0].attn.key 0.3710208468967014\n",
      "transformer.encoder_layers[0].attn.value 0.2099728054470486\n",
      "transformer.encoder_layers[0].attn.out 0.20081583658854166\n",
      "transformer.encoder_layers[0].norm2 1.0\n",
      "transformer.encoder_layers[0].mlp.fc1 0.24737591213650173\n",
      "transformer.encoder_layers[0].mlp.fc2 0.16192330254448783\n",
      "transformer.encoder_layers[1].norm1 0.9986979166666666\n",
      "transformer.encoder_layers[1].attn.query 0.3634745279947917\n",
      "transformer.encoder_layers[1].attn.key 0.3591766357421875\n",
      "transformer.encoder_layers[1].attn.value 0.3278893364800347\n",
      "transformer.encoder_layers[1].attn.out 0.4239976671006944\n",
      "transformer.encoder_layers[1].norm2 1.0\n",
      "transformer.encoder_layers[1].mlp.fc1 0.30961354573567706\n",
      "transformer.encoder_layers[1].mlp.fc2 0.2048611111111111\n",
      "transformer.encoder_layers[2].norm1 1.0\n",
      "transformer.encoder_layers[2].attn.query 0.3256005181206597\n",
      "transformer.encoder_layers[2].attn.key 0.3093075222439236\n",
      "transformer.encoder_layers[2].attn.value 0.4781867133246528\n",
      "transformer.encoder_layers[2].attn.out 0.5950537787543403\n",
      "transformer.encoder_layers[2].norm2 1.0\n",
      "transformer.encoder_layers[2].mlp.fc1 0.3294965955946181\n",
      "transformer.encoder_layers[2].mlp.fc2 0.2038396199544271\n",
      "transformer.encoder_layers[3].norm1 1.0\n",
      "transformer.encoder_layers[3].attn.query 0.3013068305121528\n",
      "transformer.encoder_layers[3].attn.key 0.2936977810329861\n",
      "transformer.encoder_layers[3].attn.value 0.5601145426432291\n",
      "transformer.encoder_layers[3].attn.out 0.6694997151692709\n",
      "transformer.encoder_layers[3].norm2 1.0\n",
      "transformer.encoder_layers[3].mlp.fc1 0.3384331597222222\n",
      "transformer.encoder_layers[3].mlp.fc2 0.2254426744249132\n",
      "transformer.encoder_layers[4].norm1 1.0\n",
      "transformer.encoder_layers[4].attn.query 0.2992062038845486\n",
      "transformer.encoder_layers[4].attn.key 0.2996690538194444\n",
      "transformer.encoder_layers[4].attn.value 0.6152157253689237\n",
      "transformer.encoder_layers[4].attn.out 0.7003631591796875\n",
      "transformer.encoder_layers[4].norm2 1.0\n",
      "transformer.encoder_layers[4].mlp.fc1 0.3413590325249566\n",
      "transformer.encoder_layers[4].mlp.fc2 0.26251135932074654\n",
      "transformer.encoder_layers[5].norm1 1.0\n",
      "transformer.encoder_layers[5].attn.query 0.3077528211805556\n",
      "transformer.encoder_layers[5].attn.key 0.3158281114366319\n",
      "transformer.encoder_layers[5].attn.value 0.6692301432291666\n",
      "transformer.encoder_layers[5].attn.out 0.7163730197482638\n",
      "transformer.encoder_layers[5].norm2 1.0\n",
      "transformer.encoder_layers[5].mlp.fc1 0.3492075602213542\n",
      "transformer.encoder_layers[5].mlp.fc2 0.30020904541015625\n",
      "transformer.encoder_layers[6].norm1 1.0\n",
      "transformer.encoder_layers[6].attn.query 0.3020070393880208\n",
      "transformer.encoder_layers[6].attn.key 0.3206634521484375\n",
      "transformer.encoder_layers[6].attn.value 0.6616448296440972\n",
      "transformer.encoder_layers[6].attn.out 0.7030080159505209\n",
      "transformer.encoder_layers[6].norm2 1.0\n",
      "transformer.encoder_layers[6].mlp.fc1 0.3544044494628906\n",
      "transformer.encoder_layers[6].mlp.fc2 0.32462310791015625\n",
      "transformer.encoder_layers[7].norm1 1.0\n",
      "transformer.encoder_layers[7].attn.query 0.3205413818359375\n",
      "transformer.encoder_layers[7].attn.key 0.3381941053602431\n",
      "transformer.encoder_layers[7].attn.value 0.6815880669487847\n",
      "transformer.encoder_layers[7].attn.out 0.6973487006293403\n",
      "transformer.encoder_layers[7].norm2 1.0\n",
      "transformer.encoder_layers[7].mlp.fc1 0.35510338677300346\n",
      "transformer.encoder_layers[7].mlp.fc2 0.35285356309678817\n",
      "transformer.encoder_layers[8].norm1 1.0\n",
      "transformer.encoder_layers[8].attn.query 0.3209940592447917\n",
      "transformer.encoder_layers[8].attn.key 0.3403981526692708\n",
      "transformer.encoder_layers[8].attn.value 0.6939205593532987\n",
      "transformer.encoder_layers[8].attn.out 0.6627451578776041\n",
      "transformer.encoder_layers[8].norm2 0.9986979166666666\n",
      "transformer.encoder_layers[8].mlp.fc1 0.36197492811414933\n",
      "transformer.encoder_layers[8].mlp.fc2 0.3918338351779514\n",
      "transformer.encoder_layers[9].norm1 1.0\n",
      "transformer.encoder_layers[9].attn.query 0.3504536946614583\n",
      "transformer.encoder_layers[9].attn.key 0.3586188422309028\n",
      "transformer.encoder_layers[9].attn.value 0.7121819390190972\n",
      "transformer.encoder_layers[9].attn.out 0.6829359266493056\n",
      "transformer.encoder_layers[9].norm2 1.0\n",
      "transformer.encoder_layers[9].mlp.fc1 0.3982832166883681\n",
      "transformer.encoder_layers[9].mlp.fc2 0.4669168260362413\n",
      "transformer.encoder_layers[10].norm1 1.0\n",
      "transformer.encoder_layers[10].attn.query 0.3067660861545139\n",
      "transformer.encoder_layers[10].attn.key 0.3168911404079861\n",
      "transformer.encoder_layers[10].attn.value 0.6817237006293403\n",
      "transformer.encoder_layers[10].attn.out 0.687103271484375\n",
      "transformer.encoder_layers[10].norm2 1.0\n",
      "transformer.encoder_layers[10].mlp.fc1 0.45620134141710067\n",
      "transformer.encoder_layers[10].mlp.fc2 0.5554805331759982\n",
      "transformer.encoder_layers[11].norm1 1.0\n",
      "transformer.encoder_layers[11].attn.query 0.4022284613715278\n",
      "transformer.encoder_layers[11].attn.key 0.4238552517361111\n",
      "transformer.encoder_layers[11].attn.value 0.8248002794053819\n",
      "transformer.encoder_layers[11].attn.out 0.7899915907118056\n",
      "transformer.encoder_layers[11].norm2 1.0\n",
      "transformer.encoder_layers[11].mlp.fc1 0.40985743204752606\n",
      "transformer.encoder_layers[11].mlp.fc2 0.4762950473361545\n",
      "transformer.norm 1.0\n",
      "classifier 0.9856770833333334\n"
     ]
    }
   ],
   "source": [
    "temp = 0\n",
    "all_num = 0\n",
    "for layer in layer_remove:\n",
    "    temp += layer_remove[layer].sum()\n",
    "    all_num += layer_remove[layer].size\n",
    "    print(layer, layer_remove[layer].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3861793079619073"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp / all_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b6b2e01b514451fa8637e10428f6371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始准确率 0.9849\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_model()\n",
    "    correct, all = test_model(net, test_dataloader_all)\n",
    "    print(\"原始准确率\", correct / all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22dd3fdf58454850ab8383c815141184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "现在准确率 0.9248\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_model()\n",
    "    for layer in all_layer_names:\n",
    "        # if len(eval(\"net.\" + layer + \".weight.shape\")) == 2:\n",
    "        try:\n",
    "            exec(\"net.\" + layer + \".weight[~layer_remove[layer]] = 0\")\n",
    "        except:\n",
    "            exec(\"net.\" + layer + \".weight[~layer_remove[layer],:] = 0\")\n",
    "        # exec(\"net.\" + layer + \".weight[~layer_remove[layer]] = 0\")\n",
    "    correct, all = test_model(net, test_dataloader_all)\n",
    "    print(\"现在准确率\", correct / all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n",
      "tensor(0., device='cuda:0', grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for key,value in layer_remove.items():\n",
    "    print((eval(\"net.\" + key + \".weight\")[np.where(value == False)]).sum())\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([768, 3, 16, 16])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval(\"net.\" + list(layer_remove.keys())[0] + \".weight\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ca616e31a74ce79605222185d2880c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/313 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "去掉最大准确率 0.0962\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    net = load_model()\n",
    "    for layer in all_layer_names:\n",
    "        keep_rate = layer_remove[layer].sum() / layer_remove[layer].size\n",
    "        weight_flatten = eval(\"net.\" + layer + \".weight.cpu().detach().numpy()\").flatten()\n",
    "        threshold = np.sort(weight_flatten)[int(len(weight_flatten) * (1 - keep_rate))]\n",
    "        try:\n",
    "            exec(\"net.\" + layer + \".weight[eval('net.' + layer + '.weight.cpu().detach().numpy()') < threshold] = 0\")\n",
    "        except:\n",
    "            exec(\"net.\" + layer + \".weight[eval('net.' + layer + '.weight.cpu().detach().numpy()') < threshold,:] = 0\")\n",
    "    correct, all = test_model(net, test_dataloader_all)\n",
    "    print(\"去掉最大准确率\", correct / all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "c1050a06cbaeed8b46d187604389f32b45fa537b377a0b8f76b38e0c23b5abbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

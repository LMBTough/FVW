{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_cifar10\n",
    "from torchvision import transforms as T\n",
    "from finetune.models.resnet import resnet50\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = resnet50()\n",
    "state_dict = torch.load('weights/cifar10_resnet50_weights.pth')\n",
    "for key in list(state_dict.keys()):\n",
    "    if 'module' in key:\n",
    "        state_dict[key.replace('module.', '')] = state_dict[key]\n",
    "        del state_dict[key]\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.eval().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "net = copy.deepcopy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_dataloaders, test_dataloaders, train_dataloader_all, test_dataloader_all = load_cifar10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_backward(net, train_loader, loss_fn):\n",
    "    total_loss = 0\n",
    "    num = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = net(x)\n",
    "        loss = loss_fn(outputs, y)\n",
    "        total_loss = loss.item() + total_loss\n",
    "        loss.backward()\n",
    "        num += x.shape[0]\n",
    "    return total_loss, num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_all_params(net,alpha,parameter_names,operation):\n",
    "    all_grads = dict()\n",
    "    for name, param in net.named_parameters():\n",
    "        if name in parameter_names:\n",
    "            grads = param.grad.data\n",
    "            weights = param.data\n",
    "            if operation == 'add':\n",
    "                mask = ((weights < 0) & (grads < 0)) ^ ((weights > 0) & (grads > 0))\n",
    "            elif operation == 'minus':\n",
    "                mask = ~(((weights < 0) & (grads < 0)) ^ ((weights > 0) & (grads > 0)))\n",
    "            param.data = weights + alpha * grads.sign() * mask.float()\n",
    "            all_grads[name] = grads\n",
    "    return all_grads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_attribution(parameter_names,weight_attribution,num,grads_before,grads,alpha,operation):\n",
    "    if operation == 'minus':\n",
    "        alpha = -alpha\n",
    "    for name in parameter_names:\n",
    "        if weight_attribution[name] is None:\n",
    "            weight_attribution[name] = alpha * grads_before[name].sign() * (grads_before[name] + grads[name]) / num / 2\n",
    "        else:\n",
    "            weight_attribution[name] += alpha * grads_before[name].sign() * (grads_before[name] + grads[name]) / num / 2\n",
    "    return weight_attribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "parameter_names = [name for name, param in net.named_parameters() if param.requires_grad]\n",
    "weight_attribution = dict()\n",
    "for name in parameter_names:\n",
    "    weight_attribution[name] = None\n",
    "start_loss = None\n",
    "end_loss = None\n",
    "grads_before = None\n",
    "grads = None\n",
    "num_steps = 2\n",
    "alpha = 1e-8\n",
    "operation = 'minus'\n",
    "for i in range(num_steps + 1):\n",
    "    total_loss, num = forward_backward(net, train_dataloader_all, loss_fn)\n",
    "    if i == 0:\n",
    "        start_loss = total_loss / num\n",
    "        grads_before = update_all_params(net,alpha,parameter_names,operation)\n",
    "    else:\n",
    "        grads = update_all_params(net,alpha,parameter_names,operation)\n",
    "        weight_attribution = update_attribution(parameter_names,weight_attribution,num,grads_before,grads,alpha,operation)\n",
    "        grads_before = grads\n",
    "        end_loss = total_loss / num\n",
    "    net.zero_grad()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "model_state_dict = model.state_dict()\n",
    "combine = dict()\n",
    "combine_flatten = list()\n",
    "for name in parameter_names:\n",
    "    combine[name] = (weight_attribution[name] * model_state_dict[name]).abs()\n",
    "    combine_flatten.append(combine[name].flatten())\n",
    "combine_flatten = torch.cat(combine_flatten)\n",
    "combine_flatten = combine_flatten.cpu().detach().numpy()\n",
    "threshold = np.percentile(combine_flatten, 60)\n",
    "mask = dict()\n",
    "for name in parameter_names:\n",
    "    mask[name] = combine[name] > threshold\n",
    "    model_state_dict[name] = mask[name] * model_state_dict[name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_copy = copy.deepcopy(model)\n",
    "model_copy.load_state_dict(model_state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9347\n"
     ]
    }
   ],
   "source": [
    "test_preds = []\n",
    "test_labels = []\n",
    "with torch.no_grad():\n",
    "    for x, y in test_dataloader_all:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = model_copy(x)\n",
    "        test_preds.append(F.softmax(outputs, dim=1).cpu().numpy())\n",
    "        test_labels.append(y.cpu().numpy())\n",
    "test_preds = np.concatenate(test_preds)\n",
    "test_labels = np.concatenate(test_labels)\n",
    "test_preds = np.argmax(test_preds, axis=1)\n",
    "acc = np.mean(test_preds == test_labels)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
